{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyObUZ5sh5/aLk7TUNLKrbeN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["코드 4-1 파이토치를 사용한 MLP"],"metadata":{"id":"yfUhzj-0EFGk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJ-aMzZ-EERZ"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MultilayerPerceptron(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        \"\"\"\n","        매개변수\n","            input_dim (int): 입력 벡터 크기\n","            hidden_dim (int): 첫 번째 Linear 층의 출력 크기\n","            output_dim (int): 두 번째 Linear 층의 출력 크기\n","        \"\"\"\n","        super(MultilayerPerceptron, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x_in, apply_softmax=False):\n","        \"\"\"MLP의 정방향 계산\n","\n","        매개변수:\n","            x_in (torch.Tensor): 입력 데이터 텐서\n","                x_in.shape는 (batch, input_dim) 입니다.\n","            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n","                크로스 엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n","        반환값:\n","            결과 텐서. tensor.shape은 (batch, output_dim) 입니다.\n","        \"\"\"\n","        intermediate = F.relu(self.fc1(x_in))\n","        output = self.fc2(intermediate)\n","\n","        if apply_softmax:\n","            output = F.softmax(output, dim=1)\n","        return output\n"]},{"cell_type":"markdown","source":["코드 4-2 MLP 객체 생성"],"metadata":{"id":"7cijYmXCGHCE"}},{"cell_type":"code","source":["batch_size = 2 # 한 번에 입력할 샘플 개수\n","input_dim = 3\n","hidden_dim = 100\n","output_dim = 4\n","\n","# 모델 생성\n","mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)\n","print(mlp)"],"metadata":{"id":"P4b6kaILGJjP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["코드4-3 랜덤한 입력으로 MLP 테스트하기"],"metadata":{"id":"AYVVVhgrdrig"}},{"cell_type":"code","source":["import torch\n","\n","def describe(x):\n","    print(\"타입: {}\".format(x.type))\n","    print(\"크기: {}\".format(x.shape))\n","    print(\"값: \\n{}\".format(x))\n","\n","x_input = torch.rand(batch_size, input_dim)\n","describe(x_input)"],"metadata":{"id":"fbPJ4mQqGd2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_output = mlp(x_input, apply_softmax=False)\n","describe(y_output)"],"metadata":{"id":"9uvOrNRqeNIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_output = mlp(x_input, apply_softmax=True)\n","describe(y_output)"],"metadata":{"id":"pZ5JyIbbeV4r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2 예제: MLP로 성씨 분류하기"],"metadata":{"id":"zCT1QFBUeyP3"}},{"cell_type":"markdown","source":["### 4.2.1 성씨 데이터셋"],"metadata":{"id":"2L3MpJI6r-Zd"}},{"cell_type":"markdown","source":["#### 코드4-5 SurnameDataset.__getitem__()구현"],"metadata":{"id":"BR2_62FwsCey"}},{"cell_type":"code","source":["class SurnameDataset(Dataset):\n","    # [코드 3-14]와 구현이 매우 비슷합니다.\n","\n","    def __getitem__(self, index):\n","        row = self._target_df.iloc[index]\n","        surname_vector = \\\n","            self._vectorizer.vectorize(row.surname)\n","        nationality_index = \\\n","            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n","\n","        return {'x_surname': surname_vector,\n","                'y_nationality': nationality_index}\n"],"metadata":{"id":"mzB5FpBYewZK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-6 SurnameVectorizer 구현"],"metadata":{"id":"_aVxe9NMz_YW"}},{"cell_type":"code","source":["class SurnameVectorizer(object):\n","    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n","    def __init__(self, surname_vocab, nationality_vocab):\n","        self.surname_vocab = surname_vocab\n","        self.nationality_vocab = nationality_vocab\n","\n","    def vectorize(self, surname):\n","        \"\"\" 성씨에 대한 원-핫 벡터를 만듭니다\n","\n","        매개변수:\n","            surname (str): 성씨\n","        반환값:\n","            one_hot (np.ndarray): 원-핫 벡터\n","        \"\"\"\n","        vocab = self.surname_vocab\n","        one_hot = np.zeros(len(vocab), dtype=np.float32)\n","        for token in surname:\n","            one_hot[vocab.lookup_token(token)] = 1\n","        return one_hot\n","\n","\n","        @classmethod\n","        def from_dataframe(cls, surname_df):\n","            \"\"\" 데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n","\n","            매개변수:\n","                surname_df (pandas.DataFrame): 성씨 데이터셋\n","            반환값:\n","                SurnameVectorizer 객체\n","            \"\"\"\n","            surname_vocab = Vocabulary(unk_token=\"@\")\n","            nationality_vocab = Vocabulary(add_unk=False)\n","\n","            for index, row in surname_df.iterrows():\n","                for letter in row.surname:\n","                    surname_vocab.add_token(letter)\n","                nationality_vocab.add_token(row.nationality)\n","\n","            return cls(surname_vocab, nationality_vocab)"],"metadata":{"id":"z_VSzGme0Ei9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-7 MLP 기반의 SurnameClassifier"],"metadata":{"id":"gxD_CzlVhtsN"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SurnameClassifier(nn.Module):\n","    \"\"\" 성씨 분류를 의한 MLP \"\"\"\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        \"\"\"\n","        매개변수:\n","            input_dim (int): 입력 벡터 크기\n","            hidden_dim (int): 첫번째 Linear 층의 출력 크기\n","            output_dim (int): 두번째 Linear 층의 출력 크기\n","        \"\"\"\n","        super(SurnameClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x_in, apply_softmax=False):\n","        \"\"\" MLP의 정방향 계산\n","\n","        매개변수:\n","            x_in (torch.Tensor): 입력 데이터 텐서\n","                x_in.shape는 (batch, input_dim) 입니다.\n","            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n","                크로스 엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n","        반환값:\n","            결과 텐서. tensor.shape은 (batch, output_dim) 입니다.\n","        \"\"\"\n","        intermediate_vector = F.relu(self.fc1(x_in))\n","        prediction_vector = self.fc2(intermediate_vector)\n","\n","        if apply_softmax:\n","            prediction_vector = F.softmax(prediction_vector, dim=1)\n","\n","        return prediction_vector\n"],"metadata":{"id":"Dv7gItpJhsQO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-8. MLP 기반의 성씨 분류기를 위한 하이퍼파라미터 프로그램 설정"],"metadata":{"id":"ePLa4-QBj5Nq"}},{"cell_type":"code","source":["args = Namespace(\n","    # 날짜와 경로 정보\n","    surname_csv = \"data/surnames/surnames_with_splits.csv\",\n","    vectorizer_file = \"vectorizer.json\"\n","    model_state_file=\"model.pth\",\n","    save_dir = \"model_storage/ch4/surname_mlp\",\n","    # 모델 하이퍼파라미터\n","    hidden_dim = 300,\n","    # 훈련 하이퍼파라미터\n","    seed = 1337,\n","    num_epochs = 100,\n","    early_stopping_criteria=5,\n","    learning_rate = 0.001\n","    batch_size = 64,\n","    # 실행 옵션은 주피터 노트북을 참고하세요\n",")"],"metadata":{"id":"yVf3LjQbkBfZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-9. 데이터셋, 모델, 손실, 옵티마이저 생성"],"metadata":{"id":"C_YjQQb3lR66"}},{"cell_type":"code","source":["dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)\n","vectorizer = dataset.get_vectorizer()\n","\n","classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab),\n","                               hidden_dim=args.hidden_dim,\n","                               output_dim=len(vectorizer.nationality_vocab))\n","\n","classifier = classifier.to(args.device)\n","\n","loss_func = nn.CrossEntropyLoss(dataset.class_weights)\n","optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n"],"metadata":{"id":"nPyMjG1OlWH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-10. 훈련 반복 코드의 일부"],"metadata":{"id":"5KzGMq9z0Ifo"}},{"cell_type":"code","source":["# 훈련 과정은 5단계입니다\n","\n","# --------------------------------------------\n","# 1단계. 그레이디언트를 0으로 초기화합니다\n","optimizer.zero_grad()\n","\n","# 2단계. 출력을 계산합니다\n","y_pred = classifier(batch_dict['x_surname'])\n","\n","# 3단계. 손실을 계산합니다\n","loss = loss_func(y_pred, batch_dict['y_nationality'])\n","loss_batch = loss.to(\"cpu\").item()\n","running_loss += (loss_batch - running_loss) / (batch_index + 1)\n","\n","# 4단계. 손실을 사용해 그레이디언트를 계산합니다\n","loss.backward()\n","\n","# 5단계. 옵티마이저로 가중치를 업데이트합니다\n","optimizer.step()\n"],"metadata":{"id":"w3mPikI80Ogy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-11. 기존 모델(분류기)을 사용한 추론: 주어진 이름의 국적 예측하기\n"],"metadata":{"id":"YurDiPaa3lGU"}},{"cell_type":"code","source":["def predict_nationality(name, clasifier, vectorizer):\n","    vectorized_name = vectorizer.vectorize(name)\n","    vectorized_name = torch.tensor(vectorized_name).view(1, -1)\n","    result = classifier(vectorized_name, apply_softmax=True)\n","\n","    probability_values, indices = result.max(dim=1)\n","    index = indices.item()\n","\n","    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)\n","    probability_value = probability_values.item()\n","\n","    return {'nationality': predicted_nationality,\n","            'probability': probability_value}"],"metadata":{"id":"zAXcgL-p3kEg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 코드 4-12. 새로운 성씨에 대해 최상위 k개 예측 만들기"],"metadata":{"id":"G55DgLGI4-1V"}},{"cell_type":"code","source":["def predict_topk_nationality(name, classifier, vectorizer, k=5):\n","    vectorized_name = vectorizer.vectorize(name)\n","    vectorized_name = torch.tensor(vectorized_name).view(1, -1)\n","    prediction_vector = classifier(vectorized_name, apply_softmax=True)\n","    probability_values, indices = torch.topk(prediction_vector, k=k)\n","\n","    # 반환되는 크기는 (1, k) 입니다\n","    probability_values = probability_values.detach().numpy()[0]\n","    indices = indices.detach().numpy()[0]\n","\n","    results = []\n","    for prob_value, index in zip(probability_values, indices):\n","        nationality = vectorizer.nationality_vocab.lookup_index(index)\n","        results.append({'nationality': nationality,\n","                        'probability': prob_value})\n","\n","        return results"],"metadata":{"id":"B0rtqhbm0PLe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-13. 드롭아웃을 적용한 MLP"],"metadata":{"id":"z1XCc6Yuusrc"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MultilayerPerceptron(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        \"\"\"\n","        매개변수:\n","            input_dim (int): 입력 벡터 크기\n","            hidden_dim (int): 첫 번째 Linear 층의 출력 크기\n","            output_dim (int): 두 번째 Linear 층의 출력 크기\n","        \"\"\"\n","        super(MultilayerPerceptron, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, hidden_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x_in, apply_softmax=False):\n","        \"\"\" MLP의 정방향 계산\n","\n","        매개변수:\n","            x_in (torch.Tensor): 입력 데이터 텐서\n","                x_in.shape는 (batch, input_dim) 입니다.\n","            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n","                크로스 엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n","        반환값:\n","            결과 텐서. tensor.shape은 (batch, output_dim) 입니다.\n","        \"\"\"\n","        intermediate = F.relu(self.fc1(x_in))\n","        output = self.fc2(F.dropout(intermediate, p=0.5))\n","\n","        if apply_softmax:\n","            output = F.softmax(output, dim = 1)\n","        return output\n"],"metadata":{"id":"k45v6x5QuxG1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-14 인공 데이터와 Conv1d 클래스"],"metadata":{"id":"JeNqRVPb-674"}},{"cell_type":"code","source":["import torch\n","\n","batch_size = 2\n","one_hot_size = 10\n","sequence_width = 7\n","data = torch.randn(batch_size, one_hot_size, sequence_width)\n","conv1 = Conv1d(in_channels=one_hot_size, out_channels = 16,\n","               kernel_size = 3)\n","intermediate1 = conv1(data)\n","print(data.size())\n","print(intermediate1.size())"],"metadata":{"id":"KnQsZugN-_Ms"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-15 데이터에 반복 적용한 합성곱"],"metadata":{"id":"3GS_ztD848uV"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n","conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n","\n","intermediate2 = conv2(intermediate1)\n","intermediate3 = conv3(intermediate2)\n","\n","print(intermediate2.size())\n","print(intermediate3.size())\n","\n"],"metadata":{"id":"tM2GVXR9_nCs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-16 특성 벡터를 줄이는 두가지 추가 방법"],"metadata":{"id":"Dnl4MG_jodjp"}},{"cell_type":"code","source":["# 특성 벡터를 줄이는 방법 2\n","print(intermediate1.view(batch_size, -1).size())\n","\n","# 특성 벡터를 줄이는 방법 32\n","print(torch.mean(intermediate1, dim=2).size())\n","# print(torch.max(intermediate1, dim=2).size())\n","# print(torch.sum(intermediate1, dim=2).size())\n","\n"],"metadata":{"id":"7-F_tGCB_-iJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.4 예제: CNN으로 성씨 분류하기\n","\n","### 4.4.1 SurnameDataset\n","\n","### 코드 4-17 최대 성씨 길이를 전달하는 SurnameDataset"],"metadata":{"id":"cfV9C3jIpT5M"}},{"cell_type":"code","source":["class SurnameDataset(Dataset):\n","    # 4.2절 '\"예제: MLP로 성씨 분류하기(4.2절)\" 절의 구현 ...\n","\n","    def __getitem__(self, index):\n","        row = self._target_df.iloc[index]\n","\n","        surname_matrix = \\\n","            self._vectorizer.vectorize(row.surname, self._max_seq_length)\n","\n","        nationality_index = \\\n","            self._vectorizer.nationality_vocab.lookup_token(row.nationality)\n","\n","        return {'x_surname': surname_matrix,\n","                'y_nationality': nationality_index}\n"],"metadata":{"id":"DtdnZjehpbnI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.4.2 Vocabulary, Vectorizer, DataLoader\n","### 코드 4-18 CNN을 위한 SurnameVectorizer 구현"],"metadata":{"id":"UFvqFvcMtjbJ"}},{"cell_type":"code","source":["clss SurnameVectorizer(object):\n","    \"\"\" 어휘 사전을 생성하고 관리합니다 \"\"\"\n","    def vectorize(self, surname):\n","        \"\"\" 성씨에 대한 원-핫 벡터를 만듭니다\n","\n","        매개변수:\n","            surname (str): 성씨\n","        반환값:\n","            one_hot (np.ndarray): 원-핫 벡터의 정렬\n","        \"\"\"\n","        one_hot_matrix_size = (len(self.character_vocab), self.max_surname_length)\n","        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)\n","        for position_index, character in enumerate(surname):\n","            character_index = self.character_vocab.lookup_token(character)\n","            one_hot_matrix[character_index][position_index] = 1\n","\n","        return one_hot_matrix\n","\n","    @classmethod\n","    def from_dataframe(cls, surname_df):\n","        \"\"\" 데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n","\n","        매개변수:\n","            surname_df (pandas.DataFrame): 성씨 데이터셋\n","        반환값:\n","            SurnameVectorizer 객체\n","        \"\"\"\n","        character_vocab = Vocabulary(unk_token=\"@\")\n","        nationality_vocab = Vocabulary(add_unk=False)\n","        max_surname_length = 0\n","\n","        for index, row in surname_df.iterrows():\n","            max_surname_length = max(max_surname_length, len(row.surname))\n","            for letter in row.surname:\n","                character_vocab.add_token(letter)\n","            nationality_vocab.add_token(row.nationality)\n","\n","        return cls(character_vocab, nationality_vocab, max_surname_length)\n"],"metadata":{"id":"-QDo_u4Ytt5q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-19 CNN 기반의 SurnameClassifier"],"metadata":{"id":"KX6gKUk88Cak"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SurnameClassifier(nn.Module):\n","    def _init_(self, initial_num_channels, num_classes, num_channels):\n","        \"\"\"\n","        매개변수:\n","            initial_num_channels (int): 입력 특성 벡터의 크기\n","            num_classes (int): 출력 예측 벡터의 크기\n","        \"\"\"\n","        super(SurnameClassifier, self).__init__()\n","\n","        self.convnet = nn.Sequential(\n","            nn.Conv1d(in_channels=initial_num_channels,\n","                      out_channels=num_channels, kernel_size=3),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n","                      kernel_size=3, stride=2),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n","                      kernel_size=3, stride=2),\n","            nn.ELU(),\n","            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,\n","                      kernel_size=3),\n","            nn.ELU()\n","        )\n","        self.fc = nn.Linear(num_channels, num_classes)\n","\n","    def forward(self, x_surname, apply_softmax=False):\n","        \"\"\" 모델의 정방향 계산\n","\n","        매개변수:\n","            x_surname (torch.Tensor): 입력 데이터 텐서\n","                x_surname.shape은 (batch, initial_num_channels, max_surname_length) 입니다.\n","            apply_softmax (bool): 소프트맥스 활성화 함수를 위한 플래그\n","                크로스 엔트로피 손실을 사용하려면 False로 지정해야 합니다.\n","            반환값:\n","                결과 텐서. tensor.shape은 (batch, num_classes)입니다.\n","        \"\"\"\n","        features = self.convnet(x_surname).squeeze(dim2)\n","        prediction_vector = self.fc(features)\n","\n","        if apply_softmax:\n","            prediction_vector = F.softmax(prediction_vector, dim=1)\n","\n","        return prediction_vector\n"],"metadata":{"id":"zlz6aYcY8MWK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 코드 4-20 CNN 성씨 분류기의 입력 매개변수"],"metadata":{"id":"6OYSdGl7AgHY"}},{"cell_type":"code","source":["args = Namespace(\n","    # 날짜와 경로 정보\n","    surname_csv=\"data/surnames/surnames_with_splits.csv\",\n","    vectorizer_file=\"vectorizer.json\",\n","    model_state_file=\"model.pth\",\n","    save_dir=\"model_storage/ch4/cnn\",\n","    # 모델 하이퍼파라미터\n","    hidden_dim=100,\n","    num_channels=256,\n","    # 훈련 하이퍼파라미터\n","    seed=1337,\n","    learning_rate=0.001,\n","    batch_size=128,\n","    num_epochs=100,\n","    early_stopping_criteria=5,\n","    dropout_p=0.1,\n","    # 실행 옵션은 주피터 노트북을 참고하세요.\n",")"],"metadata":{"id":"7mS8I8VcAoEn"},"execution_count":null,"outputs":[]}]}